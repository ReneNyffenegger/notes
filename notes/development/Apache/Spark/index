$ Apache Spark
@ Spark

Spark is a fast and general cluster computing system for → development/Big-Data.

High-level APIs in → development/languages/Scala, → development/languages/Java, → development/languages/Python, and → development/languages/R

? In contrast to → development/Apache/Hadoop/MapReduce, which is disk based, Spark uses memory. Apparently, this is useful for → development/Data/science/Machine-learning[machine learning] algorithms.

Spark runs on
  • → development/Apache/Hadoop (→ development/Apache/Hadoop/YARN[YARN]?)
  • Apache Mesos
  • Kubernetes
  • standalone
  • In the cloud

Spark accesses various → development/Data[data] sources.

Originally developed in 2009 in UC Berkeley's AMP lab.

Fully open sourced in 2010 - now a top level project at the Apache Software Foundation


{ Documentation

  → http://spark.apache.org/documentation.html

  → https://cwiki.apache.org/confluence/display/SPARK

}

{ Concepts

  → development/misc/RDD

  Transformations

  Actions

}

{ TODOs


  MLlib: machine learning

  GraphX: graph processing

  Spark Streaming


}
sa:
  → development/databases/SQL-Server/Big-Data-Clusters[SQL Server: Big Data Clusters]

links:

  → http://spark.apache.org.

  → http://github.com/apache/spark

