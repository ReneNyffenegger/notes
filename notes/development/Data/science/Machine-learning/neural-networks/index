
Neural networks are *non-linear* → science/mathematics/statistics/model[models].


Applications:
  • Image recognition


{ Neurons

  A neuron can be thought of as a cell that contains a number between 0 and 1. This number is also called *activation*.

}
{ Sigmoid function

  σ(x) = 1/(1 + exp(-x))

  For all x, the sigmoid function produced a value between 0 and 1.

  A particularly useful property of the sigmoid function is that that its derivative is
  -
  σ' = ó * (1-σ)



}
{ TODO

 { Autoencoders #todo-autoencoders

  *Autoencoders* is a type of *artificial neural network* used to learn efficient data codings in an unsupervised manner.

   An autoencoder tries to learn the *identity function* (that is: to reconstruct its input). This entails that
   the autoencoder has the equal amount of input and output neurons.
   -
   An additional requirement for an autoencoder is that the number of neurons in the hidden layer must be less than
   the number of input/output neurons. This second requirement forces the autoencoder to learn the most important
   features of the input only.

   An autoencoder consists of
      • The encoding function (*encoder*)
      • The decoding function (*decoder*)
      • A distaance function (*loss function*)

   Autoencoders are relevant for → development/Data/quality[data quality].


  }

}
