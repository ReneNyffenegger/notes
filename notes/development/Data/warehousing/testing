$ Datawarehouse testing


{ Functional tests

  Does the data meet the specified business requirements and objectives?

  Are there metrics for *data quality*? Who defines them?

  Is there test (synthetic) data?
  -
  Does the volume of the test data correspond to the live volume?

  Is the data complete or is some missing?

  Does *data tranformation* actually enhance the value of data?

  Are there *forced error* tests to check if and how the system can handle faulty data?

  Compare → development/Data/OLAP results with data queried from the source → development/databases[database].

}
{ Quality tests

  Organizations for which information (data) is a main asset for strategic decisions etc., need 
  to assure its quality.

}
{ Usability tests

  Are the schemas (ERD) understandable?

  How easy is it to select, join, filter etc. the needed data?

  Do access rights prevent the users from getting »their« data?

}
{ Performance tests

  How long do various tasks such as ETL, joining fact tables to dimension tables etc take?

  Is there a *definition of a reference* of
   • data volume for ETL jobs and
   • number of concurrent sessions and type of queries for normal workload?


}
{ Stress tests

  Similar to performance tests, but it discovers bottlenecks under peak loads of data and
  heavy workloads of the system.

}
{ Recovery tests

  Can data be recovered after hardware failures or accidental misoperations (`drop table...`)?

  How long does it take to recover the data?

  How can it be verified that *all* and the *most recently backed up* data is recovered?

  Who is in charge?

}
{ Security tests

  Is someone able to copy data without autorization?

  What actions (DML and DDL etc) are audited?

  Who checkes the audits? Interval of such checks?

}

sa:
  → development/Data/warehousing
