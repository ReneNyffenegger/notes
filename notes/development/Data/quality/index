$ Data quality

High quality data is critical for businesses and organizations. Incorrect data creates risks:
  • customer disatisfaction
  • compliance
  • loss of credibility

Automating becomes hard or impossible with bad data.

Incorrect data distorts the results of
  • → development/Data/analysis[data analysis]
  • reporting
  • → development/Data/mining[data mining]
  • warehousing

Last but not least, bad data quality *wastes* the time and energy of (potentially highly paid) professionals.

For these reasons, *improving data quality* is essential to
  • → development/Data/mining[data mining]
  • → development/Data/analysis[data analysis]
  • continuous process optimazation and
  • → development/Big-Data[Big Data] in general.

An important means to test data quality is the → development/Data/mining/anomaly-detection#outlier-detection[detection of outliers].

{ Assessment of data quality

  The assessment of data quality is usually a cyclic process to be carried out continuously or repetitively.

  In order to assess the quality of data, it is necessary to define the target data quality. It might be one of
    • *Schweizer Qualität*: The best possible result with no regard to cost or time.
    • A threshold specified by a *customer* or *international body* (standard).
    • Fitness for use (That is the extent that → development/Data[data] serves the purpose of the user).

}
{ Data validation

  Data validation is an attempt to falsify the assumption that the claims of the data can be accepted as facts.

}
{ Log files / process mining

  Data quality becomes increasinlgy important in unsuspected areas such as → development/log-files[log files] (event logs) because they can be
  → development/Data/analysis[analyzed] for → development/Data/mining/process[process mining].

}
{ TODO

  → development/Data/science/Machine-learning/neural-networks#todo-autoencoders[Autoencoders]

}
sa:
  → development/Data, → development/Data/cleaning
