$ The unfinished history of Artificial Intelligence

{ 1943: Theory of nets without circles #hist-ai-nn

  Warren McCulloch and Walter Pitts: → http://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf[A locigal calculus of the ideas immanent in nervous activity].

  The paper mentions a *theory of nets without circles*:
    • The activity of the neuron is an “all-or-none” process.
    • A certain fixed number of synapses must be excited within the period of latent addition in order to excite a neuron at any time, and this number is independent of previous activity and position on the neuron.
    • The only significant delay within the nervous sytem is synaptic delay.
    • The activity of any inhibitory synapse absolutely prevents excitation of the neuron at that time.
    • The structure of the net does not change with time. 

  Their ideas would later be called → development/Data/science/Machine-learning/neural-networks.

}
{ 1950: Turing test #hist-ai-turing-test

  In his paper → https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence[Computing Machinery and Intelligence], Alan Turing ponders the question: «can machines think?» and devised
  the *Turing Test*.

  The turing test states that a machine can be considered intelligent if it a human communicating with that machine cannot tell if the human is communicating with a machine or another human.

  See also → #hist-ai-eliza[ELIZA] and the → https://en.wikipedia.org/wiki/ELIZA_effect[ELIZA effect].

}
{ 1956: Dartmouth workshop #hist-ai-dartmouth

 "
   … every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it …
 " [ → http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html[A proposal for the Dartmouth summer research project on Artificial Intelligence ]

  After McCarthy persuaded the attendees to accept *Artificial Intelligence* as the name of a field of study, the → https://en.wikipedia.org/wiki/Dartmouth_workshop[Dartmouth workshop]
  is widely considered to be the founding event for the discipline of → development/Artificial-intelligence.

}
{ 1957: The perceptron (Frank Rosenblatt) #hist-ai-perceptron-rosenblatt

  See also → #hist-ai-minsky[Minsky/1969].

}
{ 1966: ELIZA, the first chatbots #hist-ai-eliza

  Joseph Weizenbaum developped → https://en.wikipedia.org/wiki/ELIZA[ELIZA], possibly the first chatbot (then called «chatterbot»).

  Conversations with ELIZA at times were so realistic that users occasionally believed to communicate with a human being and not a program (See → #hist-ai-turing-test[Turing Test]).

}
{ 1969: Perceptrons (Minsky) #hist-ai-perceptron-minsky

  Minsky and Papert published → https://en.wikipedia.org/wiki/Perceptrons_(book)[Perceptrons: an introduction to computational geometry].

  The book is thought to have had a influence on the decline in research of neural nets in the 1970s and early 1980s (AI Winter).

  The book was dedicated to Frank Rosenblatt (→ #hist-ai-perceptron-rosenblatt[Perceptron (1957)])

}
{ 1997: Deep Blue beats Garry Kasparov

  Deep Blue was the first computer to win against a reigning → https://en.wikipedia.org/wiki/World_Chess_Championship[world chess champion]: Garry Kasparov.

}
{ 2017: Attention Is All You Need

  The paper → https://arxiv.org/abs/1706.03762[Attention Is All You Need] (Vaswani et al.) introducted the *transformer architecture* which became the foundation for GPT models.

}

links:
  Jürgen Schmidhuber: → https://arxiv.org/pdf/2212.11279.pdf[The road to modern AI] - Annotated History of Modern AI and Deep Learning
