
LLaMA stands for → development/Artificial-intelligence/language-model/LLM/LLaMA → development/Artificial-intelligence/language-model/LLM[Large Language model] Meta AI.

sa:
  *Alpaca* is a training recipe based on the LLaMa 7B model uses the → https://en.wikipedia.org/wiki/Large_language_model#Instruction_tuning[Self-Instruct] method of instruction tuning
  to acquire capabilities comparable to the GPT-3.5 series *text-davinci-003* model at a modest cost.
