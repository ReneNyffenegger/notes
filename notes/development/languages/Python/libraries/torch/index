$ Python library: torch (PyTorch)

{ Multiplication

code {
>>> a = torch.tensor([ 2, 4, 3 ])
>>> a * 3
tensor([ 6, 12,  9])

>>> b = torch.tensor([ 5, 7, 2 ])
>>> torch.mul(a, b)
tensor([10, 28,  6])

>>> a * b
tensor([10, 28,  6])
code }

code {
>>> a = torch.tensor([[ 1, 2, 3, 4 ]])
>>> a
tensor([[1, 2, 3, 4]])

>>> b = torch.tensor([ [40], [30], [20], [10] ])
>>> b
tensor([[40],
        [30],
        [20],
        [10]])

>>> a*b
tensor([[ 40,  80, 120, 160],
        [ 30,  60,  90, 120],
        [ 20,  40,  60,  80],
        [ 10,  20,  30,  40]])
code }

}
{ Data types (dtype)

  Although → development/languages/Python does not distinguish between floats and doubles (they're called floats, but are double precision), In torch, there is such a distinction:
code {
>>> i = torch.tensor([ 1  , 2  , 3   ]                    ) ; i.dtype
torch.int64

>>> f = torch.tensor([ 1.1, 2.2, 3.3 ]                    ) ; f.dtype
torch.float32

>>> d = torch.tensor([ 1.1, 2.2, 3.3 ], dtype=torch.double) ; d.dtype
torch.float64
code }

}
{ pow(2).sum().item()

  The sequence `pow(2).sum().item()` might be used to calculate a *loss*:
code {
>>> import torch
>>> x = torch.tensor([1,2,3])
>>> x.pow(4)
tensor([ 1, 16, 81])

>>> x.pow(4).sum()
tensor(98)

>>> x.pow(4).sum().item()
98
code }

}
{ data.item(), backward(), grad

  Import torch and create a few simple tensors:
code {
import torch

x = torch.Tensor([3.0]).double() ; x.requires_grad = True
a = torch.Tensor([4.0]).double() ; a.requires_grad = True
b = torch.Tensor([2.0]).double() ; b.requires_grad = True
c = torch.Tensor([5.0]).double() ; c.requires_grad = True
code }

  Let `y` be dependent on `a`, `b`, `c` and `x`:
code {
y = a * x**2  +  b * x  +  c
code }

  The following prints `47.0` (= 4*3² + 2*3 + 5)
code {
print(y.data.item())
code }

  With `y.backward()`, it's possible to calculate the gradients of the variables that have an influence on the value of `y`.
code {
y.backward()
code }

  The following prints 26 (= 2ax + b)
code {
print(x.grad.item())
code }

}
{ device

code {
dev   = torch.device("cpu")
# dev = torch.device("cuda:0") # Uncomment  to run on GPU
…
rnd = torch.randn((), device=dev, dtype=torch.float)
code }

}
