-

Regression analysis seeks to find the relationship between one or more *independent variables* and a *dependent variable*.

Regression analysis is used for
  • Prediction
  • Forecasting
  • Inferring causual relationships (beware: correlation does not prove causation)

{ Methods

  • Linear regression, often fitted using least squares approach
  • → science/mathematics/statistics/model/regression-analysis/least-squares[Least squares] (Legendre 1805, Gauss 1809)
  • Least absolute deviation
  • Nonparametric regression
  • Bayesian methods (such as Bayesian linear regression)
  • Percentage regression
  • Quantile regression
  • Distance metric learning

  The terms *linear regression* and *least squares* are closely linked; but they're not synonyms.

}

{ Parameters and variables

  β is the *unknown parameter* (scalar or vector)

  X is the *independent variable*.

  Y is the *dependent variable*.

  Y ≈ f(X, β)

}
{ Robust regressions

  Non-robust regression models (such as ordinary least square) make good predictions if the underlying assumption is correct. However,
  if the underlying assumption is wrong, they give misleading information.

  Robost regression models try not to be overly affected by wrong assumptions.

  Robust regression might be used
    • when the → development/Data[data] contains outliers
    • when there is a strong suspicion of *heteroscedasticity*.

}
{ Problems

  Heteroscedasticity can invalidate *statistical tests of significance*.

}
{ Regression validation

  Regression validation tries to decide whether the results of a model (that was obtained from regression analysis) is acceptable to describe → development/Data[data].

}

sa:
  → development/Data/pattern-identification
