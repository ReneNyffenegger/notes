
A statistical model is a *formal representation of a theory* and typically expressed as a mathematically function that relates *random variables*.
-
Thus, it is a *non-deterministic* mathematical model.

Purposes:
  • Predictions
  • Extraction of information
  • Description of → science/mathematics/probability/stochastic[stochastic] structures

{ Variables

  { Continouos and categorical variables

    A variable is either continouos, discrete or categorical (qualitative).

    Categorical variables (for example hair color or gender) don't have a natural order.

    The number of children in a household is a discrete variable: there cannot be 2.3 children.

  }

  { Independent variable

    German: erklärende/unabhängige/prädiktor/eoxogene Variable

    Goes on x-axis (abscissa)

    Aka
      • explanatory variable
      • feature (→ development/Data/science/Machine-learning[machine learning] and *pattern recognition*)
      • input variable
      • predictor variable
      • regressor
      • covariate
      • control variable (used in *econometrics* for covariate)
      • controlled variable
      • manipulated variable
      • exposure variable
      • risk factor (medical statistics)

  }
  { Dependent variable #statistic-model-dependent-variable

    German: interessierende/endogene Variable - Zielvariable

    Goes on y-Axis (ordinate)

    Aka
      • response variable
      • regressand
      • predicted variable
      • measured variable
      • explained variable
      • experimental variable
      • responding variable
      • outcome variable
      • output variable
      • label

  }

}
{ Over- and underfitted models #over-and-underfitted-models

  An *overfitted model* contains more *parameters* than can be justified by the data.

  An *underfitted model* cannot adequately capture the underlying structure of the data, for example when fitting a linear model to non-linear data.

  Over- and underfitting typically occur in → development/Data/science/Machine-learning (where it is called *over-* and *undertraining*) and
  → science/mathematics/statistics/model/regression-analysis.

  Techniques to reduce overfitting:
    • model comparison
    • cross-validation
    • regularization
    • early stopping
    • pruning
    • Bayesian priors
    • dropout

}
{ TODO

  Neural networks are *non-linear* models.
 
}
